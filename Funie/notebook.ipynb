{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63d3a53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from ntpath import basename\n",
    "from os.path import join, exists\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11a4a768",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Options:\n",
    "    data_dir = \"data/A/1.jpg\"\n",
    "    sample_dir = \"data/output/\"\n",
    "    model_name = \"funiegan\"  # or \"ugan\"\n",
    "    model_path = \"models/funie_generator.pth\"\n",
    "\n",
    "opt = Options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6587482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "assert exists(opt.model_path), \"model not found\"\n",
    "os.makedirs(opt.sample_dir, exist_ok=True)\n",
    "is_cuda = torch.cuda.is_available()\n",
    "Tensor = torch.cuda.FloatTensor if is_cuda else torch.FloatTensor \n",
    "print(is_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "762cd0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if opt.model_name.lower()=='funiegan':\n",
    "    from nets import funiegan\n",
    "    model = funiegan.GeneratorFunieGAN()\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6e2e64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from models/funie_generator.pth\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(opt.model_path))\n",
    "if is_cuda: model.cuda()\n",
    "model.eval()\n",
    "print (\"Loaded model from %s\" % (opt.model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801a8b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height, channels = 512, 512, 3\n",
    "transforms_ = [transforms.Resize((img_height, img_width), Image.BICUBIC),\n",
    "               transforms.ToTensor(),\n",
    "               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),]\n",
    "transform = transforms.Compose(transforms_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f97524e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: funiegan\n",
      "Input folder: data/A/1.jpg\n",
      "Output folder: data/output/\n",
      "Looking for test images...\n",
      "Found 0 images.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model loaded: {opt.model_name}\")\n",
    "print(f\"Input folder: {opt.data_dir}\")\n",
    "print(f\"Output folder: {opt.sample_dir}\")\n",
    "print(f\"Looking for test images...\")\n",
    "\n",
    "test_files = sorted(glob(join(opt.data_dir, \"*\")))\n",
    "print(f\"Found {len(test_files)} images.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "458f7fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data/A/1.jpg\n",
      "Inference time: 1.127 sec\n",
      "Saved output to: data/output/1.jpg\n"
     ]
    }
   ],
   "source": [
    "input_image_path = \"data/A/1.jpg\"  # <-- Change this to your image path\n",
    "\n",
    "try:\n",
    "    print(f\"Processing {input_image_path}\")\n",
    "    inp_img = transform(Image.open(input_image_path).convert(\"RGB\"))\n",
    "    inp_img = Variable(inp_img).type(Tensor).unsqueeze(0)\n",
    "\n",
    "    s = time.time()\n",
    "    gen_img = model(inp_img)\n",
    "    elapsed = time.time() - s\n",
    "    print(f\"Inference time: {elapsed:.3f} sec\")\n",
    "\n",
    "    # Save result (side-by-side input and output)\n",
    "    img_sample = torch.cat((inp_img.data, gen_img.data), -1)\n",
    "    save_path = join(opt.sample_dir, basename(input_image_path))\n",
    "    save_image(img_sample, save_path, normalize=True)\n",
    "\n",
    "    print(f\"Saved output to: {save_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error processing image: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abba0502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video: data/A/vid.mp4\n",
      "Processed frame 1\n",
      "Processed frame 2\n",
      "Processed frame 3\n",
      "Processed frame 4\n",
      "Processed frame 5\n",
      "Processed frame 6\n",
      "Processed frame 7\n",
      "Processed frame 8\n",
      "Processed frame 9\n",
      "Processed frame 10\n",
      "Processed frame 11\n",
      "Processed frame 12\n",
      "Processed frame 13\n",
      "Processed frame 14\n",
      "Processed frame 15\n",
      "Processed frame 16\n",
      "Processed frame 17\n",
      "Processed frame 18\n",
      "Processed frame 19\n",
      "Processed frame 20\n",
      "Processed frame 21\n",
      "Processed frame 22\n",
      "Processed frame 23\n",
      "Processed frame 24\n",
      "Processed frame 25\n",
      "Processed frame 26\n",
      "Processed frame 27\n",
      "Processed frame 28\n",
      "Processed frame 29\n",
      "Processed frame 30\n",
      "Processed frame 31\n",
      "Processed frame 32\n",
      "Processed frame 33\n",
      "Processed frame 34\n",
      "Processed frame 35\n",
      "Processed frame 36\n",
      "Processed frame 37\n",
      "Processed frame 38\n",
      "Processed frame 39\n",
      "Processed frame 40\n",
      "Processed frame 41\n",
      "Processed frame 42\n",
      "Processed frame 43\n",
      "Processed frame 44\n",
      "Processed frame 45\n",
      "Processed frame 46\n",
      "Processed frame 47\n",
      "Processed frame 48\n",
      "Processed frame 49\n",
      "Processed frame 50\n",
      "Processed frame 51\n",
      "Processed frame 52\n",
      "Processed frame 53\n",
      "Processed frame 54\n",
      "Processed frame 55\n",
      "Processed frame 56\n",
      "Processed frame 57\n",
      "Processed frame 58\n",
      "Processed frame 59\n",
      "Processed frame 60\n",
      "Processed frame 61\n",
      "Processed frame 62\n",
      "Processed frame 63\n",
      "Processed frame 64\n",
      "Processed frame 65\n",
      "Processed frame 66\n",
      "Processed frame 67\n",
      "Processed frame 68\n",
      "Processed frame 69\n",
      "Processed frame 70\n",
      "Processed frame 71\n",
      "Processed frame 72\n",
      "Processed frame 73\n",
      "Processed frame 74\n",
      "Processed frame 75\n",
      "Processed frame 76\n",
      "Processed frame 77\n",
      "Processed frame 78\n",
      "Processed frame 79\n",
      "Processed frame 80\n",
      "Processed frame 81\n",
      "Processed frame 82\n",
      "Processed frame 83\n",
      "Processed frame 84\n",
      "Processed frame 85\n",
      "Processed frame 86\n",
      "Processed frame 87\n",
      "Processed frame 88\n",
      "Processed frame 89\n",
      "Processed frame 90\n",
      "Processed frame 91\n",
      "Processed frame 92\n",
      "Processed frame 93\n",
      "Processed frame 94\n",
      "Processed frame 95\n",
      "Processed frame 96\n",
      "Processed frame 97\n",
      "Processed frame 98\n",
      "Processed frame 99\n",
      "Processed frame 100\n",
      "Processed frame 101\n",
      "Processed frame 102\n",
      "Processed frame 103\n",
      "Processed frame 104\n",
      "Processed frame 105\n",
      "Processed frame 106\n",
      "Processed frame 107\n",
      "Processed frame 108\n",
      "Processed frame 109\n",
      "Processed frame 110\n",
      "Processed frame 111\n",
      "Processed frame 112\n",
      "Processed frame 113\n",
      "Processed frame 114\n",
      "Processed frame 115\n",
      "Processed frame 116\n",
      "Processed frame 117\n",
      "Processed frame 118\n",
      "Processed frame 119\n",
      "Processed frame 120\n",
      "Processed frame 121\n",
      "Processed frame 122\n",
      "Processed frame 123\n",
      "Processed frame 124\n",
      "Processed frame 125\n",
      "Processed frame 126\n",
      "Processed frame 127\n",
      "Processed frame 128\n",
      "Processed frame 129\n",
      "Processed frame 130\n",
      "Processed frame 131\n",
      "Processed frame 132\n",
      "Processed frame 133\n",
      "Processed frame 134\n",
      "Processed frame 135\n",
      "Processed frame 136\n",
      "Processed frame 137\n",
      "Processed frame 138\n",
      "Processed frame 139\n",
      "Processed frame 140\n",
      "Processed frame 141\n",
      "Processed frame 142\n",
      "Processed frame 143\n",
      "Processed frame 144\n",
      "Processed frame 145\n",
      "Processed frame 146\n",
      "Processed frame 147\n",
      "Processed frame 148\n",
      "Processed frame 149\n",
      "Processed frame 150\n",
      "Processed frame 151\n",
      "Processed frame 152\n",
      "Processed frame 153\n",
      "Processed frame 154\n",
      "Processed frame 155\n",
      "Processed frame 156\n",
      "Processed frame 157\n",
      "Processed frame 158\n",
      "Processed frame 159\n",
      "Processed frame 160\n",
      "Processed frame 161\n",
      "Processed frame 162\n",
      "Processed frame 163\n",
      "Processed frame 164\n",
      "Processed frame 165\n",
      "Processed frame 166\n",
      "Processed frame 167\n",
      "Processed frame 168\n",
      "Processed frame 169\n",
      "Processed frame 170\n",
      "Processed frame 171\n",
      "Processed frame 172\n",
      "Processed frame 173\n",
      "Processed frame 174\n",
      "Processed frame 175\n",
      "Processed frame 176\n",
      "Processed frame 177\n",
      "Processed frame 178\n",
      "Processed frame 179\n",
      "Processed frame 180\n",
      "Processed frame 181\n",
      "Processed frame 182\n",
      "Processed frame 183\n",
      "Processed frame 184\n",
      "Processed frame 185\n",
      "Processed frame 186\n",
      "Processed frame 187\n",
      "Processed frame 188\n",
      "Processed frame 189\n",
      "Processed frame 190\n",
      "Processed frame 191\n",
      "Processed frame 192\n",
      "Processed frame 193\n",
      "Processed frame 194\n",
      "Processed frame 195\n",
      "Processed frame 196\n",
      "Processed frame 197\n",
      "Processed frame 198\n",
      "Processed frame 199\n",
      "Processed frame 200\n",
      "Processed frame 201\n",
      "Processed frame 202\n",
      "Processed frame 203\n",
      "Processed frame 204\n",
      "Processed frame 205\n",
      "Processed frame 206\n",
      "Processed frame 207\n",
      "Processed frame 208\n",
      "Processed frame 209\n",
      "Processed frame 210\n",
      "Processed frame 211\n",
      "Processed frame 212\n",
      "Processed frame 213\n",
      "Processed frame 214\n",
      "Processed frame 215\n",
      "Processed frame 216\n",
      "Processed frame 217\n",
      "Processed frame 218\n",
      "Processed frame 219\n",
      "Processed frame 220\n",
      "Processed frame 221\n",
      "Processed frame 222\n",
      "Processed frame 223\n",
      "Processed frame 224\n",
      "Processed frame 225\n",
      "Processed frame 226\n",
      "Processed frame 227\n",
      "Processed frame 228\n",
      "Processed frame 229\n",
      "Processed frame 230\n",
      "Processed frame 231\n",
      "Processed frame 232\n",
      "Processed frame 233\n",
      "Processed frame 234\n",
      "Processed frame 235\n",
      "Processed frame 236\n",
      "Processed frame 237\n",
      "Processed frame 238\n",
      "Processed frame 239\n",
      "Processed frame 240\n",
      "Processed frame 241\n",
      "Processed frame 242\n",
      "Processed frame 243\n",
      "Processed frame 244\n",
      "Processed frame 245\n",
      "Processed frame 246\n",
      "Processed frame 247\n",
      "Processed frame 248\n",
      "Processed frame 249\n",
      "Processed frame 250\n",
      "Processed frame 251\n",
      "Processed frame 252\n",
      "Processed frame 253\n",
      "Processed frame 254\n",
      "Processed frame 255\n",
      "Processed frame 256\n",
      "Processed frame 257\n",
      "Processed frame 258\n",
      "Processed frame 259\n",
      "Processed frame 260\n",
      "Processed frame 261\n",
      "Processed frame 262\n",
      "Processed frame 263\n",
      "Processed frame 264\n",
      "Processed frame 265\n",
      "Processed frame 266\n",
      "Processed frame 267\n",
      "Processed frame 268\n",
      "Processed frame 269\n",
      "Processed frame 270\n",
      "Processed frame 271\n",
      "Processed frame 272\n",
      "Processed frame 273\n",
      "Processed frame 274\n",
      "Processed frame 275\n",
      "Processed frame 276\n",
      "Processed frame 277\n",
      "Processed frame 278\n",
      "Processed frame 279\n",
      "Processed frame 280\n",
      "Processed frame 281\n",
      "Processed frame 282\n",
      "Processed frame 283\n",
      "Processed frame 284\n",
      "Processed frame 285\n",
      "Processed frame 286\n",
      "Processed frame 287\n",
      "Processed frame 288\n",
      "Processed frame 289\n",
      "Processed frame 290\n",
      "Processed frame 291\n",
      "Processed frame 292\n",
      "Processed frame 293\n",
      "Processed frame 294\n",
      "Processed frame 295\n",
      "Processed frame 296\n",
      "Processed frame 297\n",
      "Processed frame 298\n",
      "Processed frame 299\n",
      "Processed frame 300\n",
      "Processed frame 301\n",
      "Processed frame 302\n",
      "Processed frame 303\n",
      "Processed frame 304\n",
      "Processed frame 305\n",
      "Processed frame 306\n",
      "Processed frame 307\n",
      "Processed frame 308\n",
      "Processed frame 309\n",
      "Processed frame 310\n",
      "Processed frame 311\n",
      "Processed frame 312\n",
      "Processed frame 313\n",
      "Processed frame 314\n",
      "Processed frame 315\n",
      "Processed frame 316\n",
      "Processed frame 317\n",
      "Processed frame 318\n",
      "Processed frame 319\n",
      "Processed frame 320\n",
      "Processed frame 321\n",
      "Processed frame 322\n",
      "Processed frame 323\n",
      "Processed frame 324\n",
      "Processed frame 325\n",
      "Processed frame 326\n",
      "Processed frame 327\n",
      "Processed frame 328\n",
      "Processed frame 329\n",
      "Processed frame 330\n",
      "Processed frame 331\n",
      "Processed frame 332\n",
      "Processed frame 333\n",
      "Processed frame 334\n",
      "Processed frame 335\n",
      "Processed frame 336\n",
      "Processed frame 337\n",
      "Processed frame 338\n",
      "Processed frame 339\n",
      "Processed frame 340\n",
      "Processed frame 341\n",
      "Processed frame 342\n",
      "Processed frame 343\n",
      "Processed frame 344\n",
      "Processed frame 345\n",
      "Processed frame 346\n",
      "Processed frame 347\n",
      "Processed frame 348\n",
      "Processed frame 349\n",
      "Processed frame 350\n",
      "Processed frame 351\n",
      "Processed frame 352\n",
      "Processed frame 353\n",
      "Processed frame 354\n",
      "Processed frame 355\n",
      "Processed frame 356\n",
      "Processed frame 357\n",
      "Processed frame 358\n",
      "Processed frame 359\n",
      "Processed frame 360\n",
      "Processed frame 361\n",
      "Processed frame 362\n",
      "Processed frame 363\n",
      "Processed frame 364\n",
      "Processed frame 365\n",
      "Processed frame 366\n",
      "Processed frame 367\n",
      "Processed frame 368\n",
      "Processed frame 369\n",
      "Processed frame 370\n",
      "Processed frame 371\n",
      "Processed frame 372\n",
      "Processed frame 373\n",
      "Processed frame 374\n",
      "Processed frame 375\n",
      "Processed frame 376\n",
      "Processed frame 377\n",
      "\n",
      "Processed 377 frames.\n",
      "Time taken: 0.95 sec at 397.10 fps\n",
      "Saved enhanced video to: data/output/enhanced_vid.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "input_video_path = \"data/A/vid.mp4\"  # <-- your video input\n",
    "output_video_path = join(opt.sample_dir, \"enhanced_\" + basename(input_video_path))\n",
    "\n",
    "try:\n",
    "    print(f\"Processing video: {input_video_path}\")\n",
    "\n",
    "    # Open video capture\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(f\"Cannot open video: {input_video_path}\")\n",
    "\n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Output writer: double width for side-by-side display\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width * 2, height))\n",
    "\n",
    "    times = []\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Resize + convert to PIL for model input\n",
    "        pil_img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)).resize((256, 256), Image.BICUBIC)\n",
    "        inp_tensor = transform(pil_img).unsqueeze(0).type(Tensor)\n",
    "\n",
    "        # Inference\n",
    "        s = time.time()\n",
    "        with torch.no_grad():\n",
    "            gen_tensor = model(inp_tensor)\n",
    "        times.append(time.time() - s)\n",
    "\n",
    "        # Convert output to numpy\n",
    "        inp_np = inp_tensor.squeeze().cpu().numpy().transpose(1, 2, 0)\n",
    "        gen_np = gen_tensor.squeeze().cpu().numpy().transpose(1, 2, 0)\n",
    "\n",
    "        # Denormalize\n",
    "        inp_np = ((inp_np * 0.5 + 0.5) * 255).astype(np.uint8)\n",
    "        gen_np = ((gen_np * 0.5 + 0.5) * 255).astype(np.uint8)\n",
    "\n",
    "        # Resize output back to original video size\n",
    "        inp_resized = cv2.resize(inp_np, (width, height))\n",
    "        gen_resized = cv2.resize(gen_np, (width, height))\n",
    "\n",
    "        # Stack side-by-side and convert to BGR for OpenCV\n",
    "        side_by_side = cv2.hconcat([\n",
    "            cv2.cvtColor(inp_resized, cv2.COLOR_RGB2BGR),\n",
    "            cv2.cvtColor(gen_resized, cv2.COLOR_RGB2BGR)\n",
    "        ])\n",
    "\n",
    "        out.write(side_by_side)\n",
    "        frame_count += 1\n",
    "        print(f\"Processed frame {frame_count}\")\n",
    "\n",
    "    # Release everything\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "    if len(times) > 1:\n",
    "        Ttime, Mtime = np.sum(times[1:]), np.mean(times[1:])\n",
    "        print(f\"\\nProcessed {frame_count} frames.\")\n",
    "        print(f\"Time taken: {Ttime:.2f} sec at {1. / Mtime:.2f} fps\")\n",
    "        print(f\"Saved enhanced video to: {output_video_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error processing video: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ab14118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video: data/A/vid.mp4\n",
      "Processed frame 1/95\n",
      "Processed frame 2/95\n",
      "Processed frame 3/95\n",
      "Processed frame 4/95\n",
      "Processed frame 5/95\n",
      "Processed frame 6/95\n",
      "Processed frame 7/95\n",
      "Processed frame 8/95\n",
      "Processed frame 9/95\n",
      "Processed frame 10/95\n",
      "Processed frame 11/95\n",
      "Processed frame 12/95\n",
      "Processed frame 13/95\n",
      "Processed frame 14/95\n",
      "Processed frame 15/95\n",
      "Processed frame 16/95\n",
      "Processed frame 17/95\n",
      "Processed frame 18/95\n",
      "Processed frame 19/95\n",
      "Processed frame 20/95\n",
      "Processed frame 21/95\n",
      "Processed frame 22/95\n",
      "Processed frame 23/95\n",
      "Processed frame 24/95\n",
      "Processed frame 25/95\n",
      "Processed frame 26/95\n",
      "Processed frame 27/95\n",
      "Processed frame 28/95\n",
      "Processed frame 29/95\n",
      "Processed frame 30/95\n",
      "Processed frame 31/95\n",
      "Processed frame 32/95\n",
      "Processed frame 33/95\n",
      "Processed frame 34/95\n",
      "Processed frame 35/95\n",
      "Processed frame 36/95\n",
      "Processed frame 37/95\n",
      "Processed frame 38/95\n",
      "Processed frame 39/95\n",
      "Processed frame 40/95\n",
      "Processed frame 41/95\n",
      "Processed frame 42/95\n",
      "Processed frame 43/95\n",
      "Processed frame 44/95\n",
      "Processed frame 45/95\n",
      "Processed frame 46/95\n",
      "Processed frame 47/95\n",
      "Processed frame 48/95\n",
      "Processed frame 49/95\n",
      "Processed frame 50/95\n",
      "Processed frame 51/95\n",
      "Processed frame 52/95\n",
      "Processed frame 53/95\n",
      "Processed frame 54/95\n",
      "Processed frame 55/95\n",
      "Processed frame 56/95\n",
      "Processed frame 57/95\n",
      "Processed frame 58/95\n",
      "Processed frame 59/95\n",
      "Processed frame 60/95\n",
      "Processed frame 61/95\n",
      "Processed frame 62/95\n",
      "Processed frame 63/95\n",
      "Processed frame 64/95\n",
      "Processed frame 65/95\n",
      "Processed frame 66/95\n",
      "Processed frame 67/95\n",
      "Processed frame 68/95\n",
      "Processed frame 69/95\n",
      "Processed frame 70/95\n",
      "Processed frame 71/95\n",
      "Processed frame 72/95\n",
      "Processed frame 73/95\n",
      "Processed frame 74/95\n",
      "Processed frame 75/95\n",
      "Processed frame 76/95\n",
      "Processed frame 77/95\n",
      "Processed frame 78/95\n",
      "Processed frame 79/95\n",
      "Processed frame 80/95\n",
      "Processed frame 81/95\n",
      "Processed frame 82/95\n",
      "Processed frame 83/95\n",
      "Processed frame 84/95\n",
      "Processed frame 85/95\n",
      "Processed frame 86/95\n",
      "Processed frame 87/95\n",
      "Processed frame 88/95\n",
      "Processed frame 89/95\n",
      "Processed frame 90/95\n",
      "Processed frame 91/95\n",
      "Processed frame 92/95\n",
      "Processed frame 93/95\n",
      "Processed frame 94/95\n",
      "Processed frame 95/95\n",
      "\n",
      "Processed 95 frames.\n",
      "Time taken: 0.16 sec at 599.52 fps\n",
      "Saved enhanced video to: data/output/enhanced_vid.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from os.path import join, basename\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Paths\n",
    "input_video_path = \"data/A/vid.mp4\"\n",
    "output_video_path = join(opt.sample_dir, \"enhanced_\" + basename(input_video_path))\n",
    "\n",
    "# Transform (assumed same as used in model training)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256), Image.BICUBIC),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "try:\n",
    "    print(f\"Processing video: {input_video_path}\")\n",
    "\n",
    "    # Open video\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(f\"Cannot open video: {input_video_path}\")\n",
    "\n",
    "    # Video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    max_frames = int(fps * 4)  # Only process first 4 seconds\n",
    "\n",
    "    # Output writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width * 2, height))\n",
    "\n",
    "    times = []\n",
    "    frame_count = 0\n",
    "\n",
    "    while frame_count < max_frames:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert frame to PIL and apply transform\n",
    "        pil_img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        inp_tensor = transform(pil_img).unsqueeze(0)\n",
    "        inp_tensor = Variable(inp_tensor).type(Tensor)\n",
    "\n",
    "        # Inference\n",
    "        s = time.time()\n",
    "        with torch.no_grad():\n",
    "            gen_tensor = model(inp_tensor)\n",
    "        times.append(time.time() - s)\n",
    "\n",
    "        # Convert tensors to numpy and denormalize\n",
    "        inp_np = inp_tensor.squeeze().cpu().numpy().transpose(1, 2, 0)\n",
    "        gen_np = gen_tensor.squeeze().cpu().numpy().transpose(1, 2, 0)\n",
    "        inp_np = ((inp_np * 0.5 + 0.5) * 255).astype(np.uint8)\n",
    "        gen_np = ((gen_np * 0.5 + 0.5) * 255).astype(np.uint8)\n",
    "\n",
    "        # Resize back to original size\n",
    "        inp_resized = cv2.resize(inp_np, (width, height))\n",
    "        gen_resized = cv2.resize(gen_np, (width, height))\n",
    "\n",
    "        # Side-by-side stack and save\n",
    "        side_by_side = cv2.hconcat([\n",
    "            cv2.cvtColor(inp_resized, cv2.COLOR_RGB2BGR),\n",
    "            cv2.cvtColor(gen_resized, cv2.COLOR_RGB2BGR)\n",
    "        ])\n",
    "        out.write(side_by_side)\n",
    "        frame_count += 1\n",
    "        print(f\"Processed frame {frame_count}/{max_frames}\")\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "    if len(times) > 0:\n",
    "        Ttime, Mtime = np.sum(times), np.mean(times)\n",
    "        print(f\"\\nProcessed {frame_count} frames.\")\n",
    "        print(f\"Time taken: {Ttime:.2f} sec at {1. / Mtime:.2f} fps\")\n",
    "        print(f\"Saved enhanced video to: {output_video_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error processing video: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a81bda61",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "test_files = sorted(glob(join(opt.data_dir, \"*.*\")))\n",
    "for path in test_files:\n",
    "    try:\n",
    "        print(f\"Processing {path}\")\n",
    "        inp_img = transform(Image.open(path).convert(\"RGB\"))\n",
    "        inp_img = Variable(inp_img).type(Tensor).unsqueeze(0)\n",
    "        s = time.time()\n",
    "        gen_img = model(inp_img)\n",
    "        times.append(time.time()-s)\n",
    "        img_sample = torch.cat((inp_img.data, gen_img.data), -1)\n",
    "        save_image(img_sample, join(opt.sample_dir, basename(path)), normalize=True)\n",
    "        print (\"Tested: %s\" % path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {path}: {e}\")\n",
    "\n",
    "\n",
    "## run-time    \n",
    "if (len(times) > 1):\n",
    "    print (\"\\nTotal samples: %d\" % len(test_files)) \n",
    "    # accumulate frame processing times (without bootstrap)\n",
    "    Ttime, Mtime = np.sum(times[1:]), np.mean(times[1:]) \n",
    "    print (\"Time taken: %d sec at %0.3f fps\" %(Ttime, 1./Mtime))\n",
    "    print(\"Saved generated images in in %s\\n\" %(opt.sample_dir))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pix2pix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
